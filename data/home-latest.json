{
  "generatedAt": "2026-03-02T13:03:50.388Z",
  "categories": [
    {
      "id": "media",
      "name": "Media Headlines",
      "zhName": "åª’ä½“å¤´æ¡",
      "description": "Broad-reach media coverage around AI, neuroscience, life science and technology",
      "zhDescription": "AI / ç¥ç»ç§‘å­¦ / ç”Ÿå‘½ç§‘å­¦ / æŠ€æœ¯ä¸»æµåª’ä½“æŠ¥é“",
      "updatedAt": 1772456603272,
      "items": [
        {
          "title": "Whatâ€™s next for Chinese open-source AI",
          "titleZh": "ä¸­å›½å¼€æºäººå·¥æ™ºèƒ½çš„ä¸‹ä¸€æ­¥æ˜¯ä»€ä¹ˆ",
          "source": "MIT Technology Review",
          "link": "https://www.technologyreview.com/2026/02/12/1132811/whats-next-for-chinese-open-source-ai/",
          "rawSummary": "MIT Technology Reviewâ€™s Whatâ€™s Next series looks across industries, trends, and technologies to give you a first look at the future. You can read the rest of them here. The past year has marked a turning point for Chinese AI. Since DeepSeek released its R1 reasoning model in January 2025, Chinese companies have repeatedly delivered AIâ€¦",
          "publishedAt": "2026-02-12T10:00:00.000Z",
          "ts": 1770890400000,
          "summary": "ã€Šéº»çœç†å·¥å­¦é™¢æŠ€æœ¯è¯„è®ºã€‹çš„â€œä¸‹ä¸€æ­¥æ˜¯ä»€ä¹ˆâ€ç³»åˆ—æ¶µç›–äº†å„ä¸ªè¡Œä¸šã€è¶‹åŠ¿å’ŒæŠ€æœ¯ï¼Œè®©æ‚¨å¯¹æœªæ¥æœ‰ä¸€ä¸ªåˆæ­¥çš„äº†è§£ã€‚",
          "judgement": {
            "frontier": 7,
            "depth": 10,
            "reach": 9,
            "total": 8.49
          },
          "tags": [
            "äººå·¥æ™ºèƒ½",
            "æŠ€æœ¯"
          ],
          "score": 8.49
        },
        {
          "title": "New Scientist recommends the quantum soundscape of Liminals - New Scientist",
          "titleZh": "ã€Šæ–°ç§‘å­¦å®¶ã€‹æ¨è Liminals çš„é‡å­éŸ³æ™¯ - ã€Šæ–°ç§‘å­¦å®¶ã€‹",
          "source": "newscientist.com",
          "link": "https://www.newscientist.com/article/mg26935840-400-new-scientist-recommends-the-quantum-soundscape-of-liminals/",
          "rawSummary": "Topics: exhibition/ review Advertisement ## Sign up to our weekly newsletter Receive a weekly dose of discovery in your inbox. We'll also keep you up to date with New Scientist events and special offers. Sign up ## More from New Scientist Explore the latest news, articles and features #### Comment ### Return of Fallout, Paradise and Silo fuels passion for bunker sci-fi Culture#### Comment ### New Scientist recommends pioneering artist Ryoji Ikeda's new work Culture#### Comment ### Alex Garlandâ€™s The Bone Temple is brutal, brilliant - and mind-blowing Culture#### Space ### Blue Planet Red is wrong about Mars â€“ but it's surprisingly poignant Culture #### Popular articles Trending New Scientist articles #### 1 [...] Trending New Scientist articles #### 1 AIs canâ€™t stop recommending nuclear strikes in war game simulations #### 2 Itâ€™s your perception of sleep thatâ€™s making you feel tired all day #### 3 The worldâ€™s most elusive colour is worth billions â€“ if we can find it #### 4 Birdwatching may reshape the brain and build its buffer against ageing #### 5 Rapamycin can add years to your life, or none at all â€“ itâ€™s a lottery #### 6 Cannibalism may explain why some orcas stay in family groups #### 7 Stone Age symbols may push back the earliest form of writing #### 8 Tiny predatory dinosaur weighed less than a chicken #### 9 Landmark vitiligo cream targets immune cells that disrupt pigmentation #### 10 Loophole found that makes quantum cloning possible Advertisement [...] Skip to content Sign in Subscribe now Subscribe now Subscribe now #### Comment # New Scientist recommends the quantum soundscape of Liminals The books, TV, games and more that New Scientist staff have enjoyed this week By Thomas Lewton 25 February 2026 A century ago, when quantum mechanics was developed, physicists felt they were peering into the abyss: everything they thought was real, wasnâ€™t. Today, we talk easily about collapsing clouds of probability and spooky action at a distance.",
          "publishedAt": "Wed, 25 Feb 2026 19:03:30 GMT",
          "ts": 1772046210000,
          "tavilyScore": 0.025450227199999998,
          "summary": "ä¸»é¢˜ï¼šå±•è§ˆ/å›é¡¾ å¹¿å‘Š ## è®¢é˜…æˆ‘ä»¬çš„æ¯å‘¨é€šè®¯ åœ¨æ‚¨çš„æ”¶ä»¶ç®±ä¸­æ¥æ”¶æ¯å‘¨çš„å‘ç°ã€‚",
          "judgement": {
            "frontier": 9,
            "depth": 8,
            "reach": 3,
            "total": 7.1954502272
          },
          "tags": [
            "ç¥ç»ç§‘å­¦",
            "ç§‘å­¦å‘ç°"
          ],
          "score": 7.1954502272
        },
        {
          "title": "The human work behind humanoid robots is being hidden",
          "titleZh": "äººå½¢æœºå™¨äººèƒŒåçš„äººç±»å·¥ä½œæ­£åœ¨è¢«éšè—",
          "source": "MIT Technology Review",
          "link": "https://www.technologyreview.com/2026/02/23/1133508/the-human-work-behind-humanoid-robots-is-being-hidden/",
          "rawSummary": "This story originally appeared in The Algorithm, our weekly newsletter on AI. To get stories like this in your inbox first, sign up here. In January, Nvidiaâ€™s Jensen Huang, the head of the worldâ€™s most valuable company, proclaimed that we are entering the era of physical AI, when artificial intelligence will move beyond language and chatbotsâ€¦",
          "publishedAt": "2026-02-23T17:05:00.000Z",
          "ts": 1771866300000,
          "summary": "è¿™ä¸ªæ•…äº‹æœ€åˆå‡ºç°åœ¨æˆ‘ä»¬å…³äºäººå·¥æ™ºèƒ½çš„æ¯å‘¨é€šè®¯ã€Šç®—æ³•ã€‹ä¸­ã€‚",
          "judgement": {
            "frontier": 7,
            "depth": 8,
            "reach": 9,
            "total": 7.83
          },
          "tags": [
            "äººå·¥æ™ºèƒ½"
          ],
          "score": 7.83
        },
        {
          "title": "Googleâ€™s Cloud AI lead on the three frontiers of model capability - TechCrunch",
          "titleZh": "è°·æ­Œçš„ Cloud äººå·¥æ™ºèƒ½ åœ¨æ¨¡å‹èƒ½åŠ›çš„ä¸‰ä¸ªå‰æ²¿é¢†åŸŸå¤„äºé¢†å…ˆåœ°ä½",
          "source": "techcrunch.com",
          "link": "https://techcrunch.com/2026/02/23/googles-cloud-ai-lead-on-the-three-frontiers-of-model-capability/",
          "rawSummary": "AI, Exclusive, Google, Vertex Russell Brandom AI Editor Russell Brandom has been covering the tech industry since 2012, with a focus on platform policy and emerging technologies. He previously worked at The Verge and Rest of World, and has written for Wired, The Awl and MITâ€™s Technology Review. He can be reached at russell.brandom@techcrunch.com or on Signal at 412-401-5489. View Bio October 13-15 San Francisco, CA Save up to $680 on your pass before February 27. Meet investors. Discover your next portfolio company. Hear from 250+ tech leaders, dive into 200+ sessions, and explore 300+ startups building whatâ€™s next. Donâ€™t miss these one-time savings. REGISTER NOW ## Most Popular Bill Gurley says that right now, the worst thing you can do for your career is play it safe [...] When I spoke with Michael, I was particularly struck by one idea I hadnâ€™t heard before. As he put it, AI models are pushing against three frontiers at once: raw intelligence, response time, and a third quality that has less to do with raw capability than with cost â€” whether a model can be deployed cheaply enough to run at massive, unpredictable scale. Itâ€™s a new way of thinking about model capabilities, and a particularly valuable one for anyone trying to push frontier models in a new direction. This interview has been edited for length and clarity. Why donâ€™t you start by walking us through your experience in AI so far, and what you do at Google? [...] Russell Brandom As a product VP at Google Cloud, Michael Gerstenhaber works mostly on Vertex, the companyâ€™s unified platform for deploying enterprise AI. It gives him a high-level view of how companies are actually using AI models, and what still needs to be done to unleash the potential of agentic AI.",
          "publishedAt": "Mon, 23 Feb 2026 19:18:42 GMT",
          "ts": 1771874322000,
          "tavilyScore": 0.81874656,
          "summary": "AIï¼Œç‹¬å®¶ï¼Œè°·æ­Œï¼ŒVertex Russell Brandom AI ç¼–è¾‘ Russell Brandom è‡ª 2012 å¹´ä»¥æ¥ä¸€ç›´æŠ¥é“ç§‘æŠ€è¡Œä¸šï¼Œé‡ç‚¹å…³æ³¨å¹³å°æ”¿ç­–å’Œæ–°å…´æŠ€æœ¯ã€‚",
          "judgement": {
            "frontier": 7,
            "depth": 8,
            "reach": 3,
            "total": 7.14874656
          },
          "tags": [
            "äººå·¥æ™ºèƒ½",
            "æ™ºèƒ½ä½“",
            "AIå®‰å…¨",
            "æŠ€æœ¯"
          ],
          "score": 7.14874656
        }
      ]
    },
    {
      "id": "research",
      "name": "Research Alert",
      "zhName": "ç ”ç©¶é€Ÿé€’",
      "description": "Research-heavy updates from journals, labs, and arXiv",
      "zhDescription": "ç§‘ç ”å¯¼å‘æ›´æ–°ï¼ˆå« arXivï¼‰",
      "updatedAt": 1772456623565,
      "items": [
        {
          "title": "From Moderation to Mediation: Can LLMs Serve as Mediators in Online Flame Wars?",
          "titleZh": "ä»è°ƒè§£åˆ°è°ƒè§£ï¼šå¤§æ¨¡å‹å¯ä»¥åœ¨ç½‘ç»œå£æ°´æˆ˜ä¸­å……å½“è°ƒè§£äººå—ï¼Ÿ",
          "source": "arXiv cs.AI",
          "link": "https://arxiv.org/abs/2512.03005",
          "rawSummary": "arXiv:2512.03005v5 Announce Type: replace Abstract: The rapid advancement of large language models (LLMs) has opened new possibilities for AI for good applications. As LLMs increasingly mediate online communication, their potential to foster empathy and constructive dialogue becomes an important frontier for responsible AI research. This work explores whether LLMs can serve not only as moderators that detect harmful content, but as mediators capable of understanding and de-escalating online conflicts. Our framework decomposes mediation into two subtasks: judgment, where an LLM evaluates the fairness and emotional dynamics of a conversation, and steering, where it generates empathetic, de-escalatory messages to guide participants toward resolution. To assess mediation quality, we construct a large Reddit-based dataset and propose a multi-stage evaluation pipeline combining principle-based scoring, user simulation, and human comparison. Experiments show that API-based models outperform open-source counterparts in both reasoning and intervention alignment when doing mediation. Our findings highlight both the promise and limitations of current LLMs as emerging agents for online social mediation.",
          "publishedAt": "2026-03-02T05:00:00.000Z",
          "ts": 1772427600000,
          "summary": "å…¬å‘Šç±»å‹ï¼šæ›¿æ¢ æ‘˜è¦ï¼šå¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆå¤§æ¨¡å‹ï¼‰çš„å¿«é€Ÿå‘å±•ä¸ºäººå·¥æ™ºèƒ½çš„è‰¯å¥½åº”ç”¨å¼€è¾Ÿäº†æ–°çš„å¯èƒ½æ€§ã€‚",
          "judgement": {
            "frontier": 9,
            "depth": 10,
            "reach": 8,
            "total": 9.08
          },
          "tags": [
            "äººå·¥æ™ºèƒ½",
            "å¤§æ¨¡å‹",
            "AIå®‰å…¨",
            "ç§‘ç ”è¿›å±•"
          ],
          "score": 9.08
        },
        {
          "title": "Animal behavioral analysis and neural encoding with transformer-based self-supervised pretraining",
          "titleZh": "åŸºäº Transformer çš„è‡ªç›‘ç£é¢„è®­ç»ƒçš„åŠ¨ç‰©è¡Œä¸ºåˆ†æå’Œç¥ç»ç¼–ç ",
          "source": "arXiv q-bio.NC",
          "link": "https://arxiv.org/abs/2507.09513",
          "rawSummary": "arXiv:2507.09513v2 Announce Type: replace Abstract: The brain can only be fully understood through the lens of the behavior it generates -- a guiding principle in modern neuroscience research that nevertheless presents significant technical challenges. Many studies capture behavior with cameras, but video analysis approaches typically rely on specialized models requiring extensive labeled data. We address this limitation with BEAST(BEhavioral Analysis via Self-supervised pretraining of Transformers), a novel and scalable framework that pretrains experiment-specific vision transformers for diverse neuro-behavior analyses. BEAST combines masked autoencoding with temporal contrastive learning to effectively leverage unlabeled video data. Through comprehensive evaluation across multiple species, we demonstrate improved performance in three critical neuro-behavioral tasks: extracting behavioral features that correlate with neural activity, and pose estimation and action segmentation in both the single- and multi-animal settings. Our method establishes a powerful and versatile backbone model that accelerates behavioral analysis in scenarios where labeled data remains scarce.",
          "publishedAt": "2026-03-02T05:00:00.000Z",
          "ts": 1772427600000,
          "summary": "å…¬å‘Šç±»å‹ï¼šæ›¿æ¢ æ‘˜è¦ï¼šå¤§è„‘åªèƒ½é€šè¿‡å…¶äº§ç”Ÿçš„è¡Œä¸ºçš„é•œå¤´æ‰èƒ½è¢«å……åˆ†ç†è§£â€”â€”è¿™æ˜¯ç°ä»£ç¥ç»ç§‘å­¦ç ”ç©¶çš„æŒ‡å¯¼åŸåˆ™ï¼Œä½†å®ƒæå‡ºäº†ã€‚",
          "judgement": {
            "frontier": 9,
            "depth": 10,
            "reach": 7,
            "total": 8.83
          },
          "tags": [
            "å¤§æ¨¡å‹",
            "ç¥ç»ç§‘å­¦",
            "ç§‘ç ”è¿›å±•"
          ],
          "score": 8.83
        },
        {
          "title": "U-CAN: Utility-Aware Contrastive Attenuation for Efficient Unlearning in Generative Recommendation",
          "titleZh": "U-CANï¼šç”Ÿæˆæ¨èä¸­æœ‰æ•ˆé—å¿˜çš„æ•ˆç”¨æ„ŸçŸ¥å¯¹æ¯”è¡°å‡",
          "source": "arXiv cs.LG",
          "link": "https://arxiv.org/abs/2602.23400",
          "rawSummary": "arXiv:2602.23400v1 Announce Type: new Abstract: Generative Recommendation (GenRec) typically leverages Large Language Models (LLMs) to redefine personalization as an instruction-driven sequence generation task. However, fine-tuning on user logs inadvertently encodes sensitive attributes into model parameters, raising critical privacy concerns. Existing Machine Unlearning (MU) techniques struggle to navigate this tension due to the Polysemy Dilemma, where neurons superimpose sensitive data with general reasoning patterns, leading to catastrophic utility loss under traditional gradient or pruning methods. To address this, we propose Utility-aware Contrastive AttenuatioN (U-CAN), a precision unlearning framework that operates on low-rank adapters. U-CAN quantifies risk by contrasting activations and focuses on neurons with asymmetric responses that are highly sensitive to the forgetting set but suppressed on the retention set. To safeguard performance, we introduce a utility-aware calibration mechanism that combines weight magnitudes with retention-set activation norms, assigning higher utility scores to dimensions that contribute strongly to retention performance. Unlike binary pruning, which often fragments network structure, U-CAN develop adaptive soft attenuation with a differentiable decay function to selectively down-scale high-risk parameters on LoRA adapters, suppressing sensitive retrieval pathways and preserving the topological connectivity of reasoning circuits. Experiments on two public datasets across seven metrics demonstrate that U-CAN achieves strong privacy forgetting, utility retention, and computational efficiency.",
          "publishedAt": "2026-03-02T05:00:00.000Z",
          "ts": 1772427600000,
          "summary": "å…¬å‘Šç±»å‹ï¼šæ–° æ‘˜è¦ï¼šç”Ÿæˆæ¨è (GenRec) é€šå¸¸åˆ©ç”¨å¤§å‹è¯­è¨€æ¨¡å‹ (å¤§æ¨¡å‹) å°†ä¸ªæ€§åŒ–é‡æ–°å®šä¹‰ä¸ºæŒ‡ä»¤é©±åŠ¨çš„åºåˆ—ç”Ÿæˆä»»åŠ¡ã€‚",
          "judgement": {
            "frontier": 9,
            "depth": 10,
            "reach": 7,
            "total": 8.83
          },
          "tags": [
            "AIå®‰å…¨",
            "ç§‘å­¦å‘ç°"
          ],
          "score": 8.83
        },
        {
          "title": "HumanMCP: A Human-Like Query Dataset for Evaluating MCP Tool Retrieval Performance",
          "titleZh": "HumanMCPï¼šç”¨äºè¯„ä¼° MCP å·¥å…·æ£€ç´¢æ€§èƒ½çš„ç±»äººæŸ¥è¯¢æ•°æ®é›†",
          "source": "arXiv cs.AI",
          "link": "https://arxiv.org/abs/2602.23367",
          "rawSummary": "arXiv:2602.23367v1 Announce Type: new Abstract: Model Context Protocol (MCP) servers contain a collection of thousands of open-source standardized tools, linking LLMs to external systems; however, existing datasets and benchmarks lack realistic, human-like user queries, remaining a critical gap in evaluating the tool usage and ecosystems of MCP servers. Existing datasets often do contain tool descriptions but fail to represent how different users portray their requests, leading to poor generalization and inflated reliability of certain benchmarks. This paper introduces the first large-scale MCP dataset featuring diverse, high-quality diverse user queries generated specifically to match 2800 tools across 308 MCP servers, developing on the MCP Zero dataset. Each tool is paired with multiple unique user personas that we have generated, to capture varying levels of user intent ranging from precise task requests, and ambiguous, exploratory commands, reflecting the complexity of real-world interaction patterns.",
          "publishedAt": "2026-03-02T05:00:00.000Z",
          "ts": 1772427600000,
          "summary": "å…¬å‘Šç±»å‹ï¼šæ–° æ‘˜è¦ï¼šæ¨¡å‹ä¸Šä¸‹æ–‡åè®®ï¼ˆMCPï¼‰æœåŠ¡å™¨åŒ…å«æ•°åƒä¸ªå¼€æºæ ‡å‡†åŒ–å·¥å…·çš„é›†åˆï¼Œå°†å¤§æ¨¡å‹é“¾æ¥åˆ°å¤–éƒ¨ç³»ç»Ÿï¼›ç„¶è€Œï¼Œç°æœ‰çš„æ•°æ®é›†å’Œbã€‚",
          "judgement": {
            "frontier": 9,
            "depth": 10,
            "reach": 7,
            "total": 8.83
          },
          "tags": [
            "ç§‘ç ”è¿›å±•"
          ],
          "score": 8.83
        },
        {
          "title": "Truncated Step-Level Sampling with Process Rewards for Retrieval-Augmented Reasoning",
          "titleZh": "å¸¦æœ‰è¿‡ç¨‹å¥–åŠ±çš„æˆªæ–­æ­¥éª¤çº§é‡‡æ ·ç”¨äºæ£€ç´¢å¢å¼ºæ¨ç†",
          "source": "arXiv cs.CL",
          "link": "https://arxiv.org/abs/2602.23440",
          "rawSummary": "arXiv:2602.23440v1 Announce Type: new Abstract: Training large language models to reason with search engines via reinforcement learning is hindered by a fundamental credit assignment problem: existing methods such as Search-R1 provide only a sparse outcome reward after an entire multi-step trajectory, making it infeasible to attribute success or failure to individual reasoning and retrieval decisions. Process-reward methods like StepSearch alleviate this by introducing step-level supervision, but rely on heuristic rewards such as TF-IDF overlap with gold documents, and still sample k complete trajectories per example, retaining high gradient variance. We propose SLATE, a framework built on two complementary ideas: (1) truncated step-level sampling, which generates k trajectories that share a common prefix and differ only at the next step, and (2) dense LLM-as-judge rewards, which replace heuristic scoring with a capable LLM evaluator that assesses the quality of each reasoning step, search query, and answer, providing richer and more reliable supervision. We theoretically prove that under the same dense reward structure, truncated sampling reduces the variance of advantage estimates by up to a factor of T compared to full-trajectory sampling for T-step trajectories, yielding lower-variance, better-targeted policy gradients. Experiments on seven QA benchmarks confirm that SLATE consistently outperforms both sparse-reward and process-reward baselines, with the largest gains on harder multi-hop tasks and smaller models.",
          "publishedAt": "2026-03-02T05:00:00.000Z",
          "ts": 1772427600000,
          "summary": "å…¬å‘Šç±»å‹ï¼šæ–° æ‘˜è¦ï¼šé€šè¿‡å¼ºåŒ–å­¦ä¹ è®­ç»ƒå¤§å‹è¯­è¨€æ¨¡å‹ä¸æœç´¢å¼•æ“è¿›è¡Œæ¨ç†å—åˆ°åŸºæœ¬ä¿¡ç”¨åˆ†é…é—®é¢˜çš„é˜»ç¢ï¼šç°æœ‰æ–¹æ³•ï¼ˆä¾‹å¦‚ Seaï¼‰ã€‚",
          "judgement": {
            "frontier": 9,
            "depth": 10,
            "reach": 7,
            "total": 8.83
          },
          "tags": [
            "å¤§æ¨¡å‹",
            "AIå®‰å…¨"
          ],
          "score": 8.83
        },
        {
          "title": "CiteAudit: You Cited It, But Did You Read It? A Benchmark for Verifying Scientific References in the LLM Era",
          "titleZh": "CiteAuditï¼šæ‚¨å¼•ç”¨äº†å®ƒï¼Œä½†æ‚¨è¯»è¿‡å®ƒå—ï¼Ÿ å¤§æ¨¡å‹æ—¶ä»£éªŒè¯ç§‘å­¦å‚è€ƒæ–‡çŒ®çš„åŸºå‡†",
          "source": "arXiv cs.CL",
          "link": "https://arxiv.org/abs/2602.23452",
          "rawSummary": "arXiv:2602.23452v1 Announce Type: new Abstract: Scientific research relies on accurate citation for attribution and integrity, yet large language models (LLMs) introduce a new risk: fabricated references that appear plausible but correspond to no real publications. Such hallucinated citations have already been observed in submissions and accepted papers at major machine learning venues, exposing vulnerabilities in peer review. Meanwhile, rapidly growing reference lists make manual verification impractical, and existing automated tools remain fragile to noisy and heterogeneous citation formats and lack standardized evaluation. We present the first comprehensive benchmark and detection framework for hallucinated citations in scientific writing. Our multi-agent verification pipeline decomposes citation checking into claim extraction, evidence retrieval, passage matching, reasoning, and calibrated judgment to assess whether a cited source truly supports its claim. We construct a large-scale human-validated dataset across domains and define unified metrics for citation faithfulness and evidence alignment. Experiments with state-of-the-art LLMs reveal substantial citation errors and show that our framework significantly outperforms prior methods in both accuracy and interpretability. This work provides the first scalable infrastructure for auditing citations in the LLM era and practical tools to improve the trustworthiness of scientific references.",
          "publishedAt": "2026-03-02T05:00:00.000Z",
          "ts": 1772427600000,
          "summary": "å…¬å‘Šç±»å‹ï¼šæ–° æ‘˜è¦ï¼šç§‘å­¦ç ”ç©¶ä¾èµ–äºå‡†ç¡®å¼•ç”¨çš„å½’å±å’Œå®Œæ•´æ€§ï¼Œä½†å¤§å‹è¯­è¨€æ¨¡å‹ (å¤§æ¨¡å‹) å¼•å…¥äº†æ–°çš„é£é™©ï¼šä¼ªé€ çš„å‚è€ƒæ–‡çŒ®çœ‹èµ·æ¥å¾ˆæ¼‚äº®ã€‚",
          "judgement": {
            "frontier": 9,
            "depth": 10,
            "reach": 7,
            "total": 8.83
          },
          "tags": [
            "äººå·¥æ™ºèƒ½",
            "å¤§æ¨¡å‹",
            "æ™ºèƒ½ä½“",
            "AIå®‰å…¨",
            "ç§‘ç ”è¿›å±•",
            "æŠ€æœ¯"
          ],
          "score": 8.83
        }
      ]
    },
    {
      "id": "trends",
      "name": "Tech Trends",
      "zhName": "æŠ€æœ¯è¶‹åŠ¿",
      "description": "Tech & biotech company moves, market changes and funding trends",
      "zhDescription": "ç§‘æŠ€/ç”Ÿç‰©åŒ»ç–—å…¬å¸åŠ¨å‘ã€å¸‚åœºå˜åŒ–ä¸æŠ•èèµ„è¶‹åŠ¿",
      "updatedAt": 1772456630387,
      "items": [
        {
          "title": "Why GPS fails in cities. And how it was brilliantly fixed",
          "titleZh": "ä¸ºä»€ä¹ˆ GPS åœ¨åŸå¸‚ä¸­å¤±æ•ˆã€‚ä»¥åŠå®ƒæ˜¯å¦‚ä½•å®Œç¾ä¿®å¤çš„",
          "source": "ScienceDaily AI",
          "link": "https://www.sciencedaily.com/releases/2025/10/251009033124.htm",
          "rawSummary": "Our everyday GPS struggles in â€œurban canyons,â€ where skyscrapers bounce satellite signals, confusing even advanced navigation systems. NTNU scientists created SmartNav, combining satellite corrections, wave analysis, and Googleâ€™s 3D building data for remarkable precision. Their method achieved accuracy within 10 centimeters during testing. The breakthrough could make reliable urban navigation accessible and affordable worldwide.",
          "publishedAt": "2025-10-09T07:31:24.000Z",
          "ts": 1759995084000,
          "summary": "æˆ‘ä»¬çš„æ—¥å¸¸ GPS åœ¨â€œåŸå¸‚å³¡è°·â€ä¸­ä¸¾æ­¥ç»´è‰°ï¼Œé‚£é‡Œçš„æ‘©å¤©å¤§â€‹â€‹æ¥¼åå°„å«æ˜Ÿä¿¡å·ï¼Œç”šè‡³è®©å…ˆè¿›çš„å¯¼èˆªç³»ç»Ÿæ„Ÿåˆ°å›°æƒ‘ã€‚",
          "judgement": {
            "frontier": 7,
            "depth": 10,
            "reach": 7,
            "total": 7.99
          },
          "tags": [
            "ç§‘å­¦å‘ç°"
          ],
          "score": 7.99
        },
        {
          "title": "Boston AI startup can predict risk of breast cancer before tumors appear - The Boston Globe",
          "titleZh": "æ³¢å£«é¡¿äººå·¥æ™ºèƒ½åˆåˆ›å…¬å¸å¯ä»¥åœ¨è‚¿ç˜¤å‡ºç°ä¹‹å‰é¢„æµ‹ä¹³è…ºç™Œé£é™© - æ³¢å£«é¡¿ç¯çƒæŠ¥",
          "source": "bostonglobe.com",
          "link": "https://www.bostonglobe.com/2026/02/24/business/breast-cancer-ai-detection-clairity/",
          "rawSummary": "Advertisement --- ğŸ’µ Quantum cybersecurity firm Aliro in Boston raised $15 millionin a deal led by Gutbrain Ventures. ğŸ”Œ EV developer Indigo Technologies in Woburn received a $4 million loan from MassDevelopmentâ€™s Emerging Technology Fund. â˜€ï¸ Community solar developer Solstice in Cambridge was acquired by Boston-based Perch Energy. Terms of the deal were not disclosed. ğŸ“¦ Supply chain software firm Dray Dog in Dover, N.H., was acquired by California-based firm CargoSprint. Terms of the deal were not disclosed. ğŸ‘‹ Software developer Code Metal in Boston hired Ryan Aytay, former chief executive of Tableau, as president and chief operating officer. ğŸ–¨ï¸ Somerville-based 3D printing company Formlabs added Rob Willett, former chief executive of Cognex, to its board of directors. [...] â¸ï¸ Maine considers a moratorium on data centers as businesses look to New England. Read more from Julia Tilton of The Daily Yonder. ğŸ Klaviyo founders give $6 million to boost MIT startups, Bostonâ€™s competitiveness. Read more from business reporter Jon Chesto. ğŸ¤‘ Boston-based Code Metal, which writes AI software to run hardware such as drones, sensors, and robots, raised $125 million in a deal led by Salesforce Ventures and including Accel, B Capital, Smith Point Capital, J2 Ventures, and RTX. The deal valued Code Metal at $1.25 billion. ğŸŒ Rare earth mineral producer Phoenix Tailings in Woburn raised $30 million of equity from investors Traxys, Eni Next, and Geodesic Alliance Fund. Phoenix also raised $10 million of debt from Nomura. Advertisement --- [...] â€œThereâ€™s much in medicine that can be a black box,â€ Lehman said. â€œWe are doing lots of research [to figure out] what are the features in a mammogram that the deep learning model is picking up on.â€ With Silicon Valley dominating in AI innovation so far, the Boston tech scene could use a lot more startups like Clairity, investors and entrepreneurs said. Health care startup investor Michael Greeley, general partner at Flare Capital in Boston, said he expects to see more and more researchers in the region creating startups that combine AI and medical data. A company like Clairity â€œunderscores the power of our community as the health care and technology sectors continue to collaborate given the proximity to each other,â€œ Greeley said.",
          "publishedAt": "Tue, 24 Feb 2026 21:16:07 GMT",
          "ts": 1771967767000,
          "tavilyScore": 1.4973077760000002,
          "summary": "å¹¿å‘Š --- ğŸ’µ æ³¢å£«é¡¿é‡å­ç½‘ç»œå®‰å…¨å…¬å¸ Aliro åœ¨ç”± Gutbrain Ventures ç‰µå¤´çš„äº¤æ˜“ä¸­ç­¹é›†äº† 1500 ä¸‡ç¾å…ƒã€‚",
          "judgement": {
            "frontier": 9,
            "depth": 6,
            "reach": 3,
            "total": 8.007307776
          },
          "tags": [
            "äººå·¥æ™ºèƒ½",
            "ç§‘ç ”è¿›å±•",
            "èƒ½æºç§‘æŠ€",
            "æŠ€æœ¯"
          ],
          "score": 8.007307776
        },
        {
          "title": "This AI finds simple rules where humans see only chaos",
          "titleZh": "è¿™ä¸ªäººå·¥æ™ºèƒ½æ‰¾åˆ°äº†äººç±»åªçœ‹åˆ°æ··ä¹±çš„ç®€å•è§„åˆ™",
          "source": "ScienceDaily AI",
          "link": "https://www.sciencedaily.com/releases/2025/12/251221091237.htm",
          "rawSummary": "A new AI developed at Duke University can uncover simple, readable rules behind extremely complex systems. It studies how systems evolve over time and reduces thousands of variables into compact equations that still capture real behavior. The method works across physics, engineering, climate science, and biology. Researchers say it could help scientists understand systems where traditional equations are missing or too complicated to write down.",
          "publishedAt": "2025-12-22T06:04:50.000Z",
          "ts": 1766383490000,
          "summary": "æœå…‹å¤§å­¦å¼€å‘çš„ä¸€ç§æ–°äººå·¥æ™ºèƒ½å¯ä»¥æ­ç¤ºæå…¶å¤æ‚ç³»ç»ŸèƒŒåçš„ç®€å•ã€å¯è¯»çš„è§„åˆ™ã€‚",
          "judgement": {
            "frontier": 9,
            "depth": 8,
            "reach": 7,
            "total": 8.17
          },
          "tags": [
            "äººå·¥æ™ºèƒ½",
            "ç”Ÿå‘½ç§‘å­¦"
          ],
          "score": 8.17
        },
        {
          "title": "MatX's $500m, QC Capital backs virtual pediatrics and The Raine Group's new partner - Axios",
          "titleZh": "MatX 5 äº¿ç¾å…ƒã€QC Capital æ”¯æŒè™šæ‹Ÿå„¿ç§‘å’Œ Raine Group çš„æ–°åˆä½œä¼™ä¼´ Axios",
          "source": "amp.axios.com",
          "link": "https://amp.axios.com/pro-rata-premium-first-look-matx-qc-capital-raine-e2e23561-c459-452d-a04c-e2d0e6cca8aa.html",
          "rawSummary": "â€¢ Evoke Security, a Washington-based cybersecurity company, raised a $4m pre-seed round led by Crosspoint Capital Partners, with participation from Red Cell Partners. Go deeper â€¢ Jampack AI, an NYC-based wholesale operations automation platform, raised a $3.2m seed led by Maveron, joined by Timber Grove Ventures. Go deeper ## Private Equity â€¢ Arcline Investment Management agreed to buy Hydraulics International, a provider of ground support equipment, mobile test systems, and specialized pumps. Go deeper â€¢ CampusWorks, backed by Atlantic Street Capital, merged with Dynamic Campus, a higher education IT services firm. dynamiccampus.com â€¢ Capital Constellation, backed by Wafra, invested in Gallatin Point Capital, a private investment firm. Go deeper [...] â€¢ Brookfield Asset Management bought U.K.-based Ori, an AI cloud provider, and merged it with its newly formed Radiant. Ori's backers include Fortitude Capital, Wa'ed Ventures, 6 Degrees Capital, Atempo Growth and NextEra Energy. Go deeper ## Public Offerings ğŸš‘ MiniMed Group, a diabetes management device business being carved out of Medtronic (NYSE: MDT), plans to raise $742m in an offering of 28 million shares priced between $25 to $28. Go deeper ğŸ’Š Salspera, a Cambridge, Mass.-based cancer biotech, plans to raise $85m by offering 5.7 million shares priced between $14 and $16. Go deeper ## It's Personnel â€¢ Anthony Kontoleon, former partner and CEO of the Americas at Azura Partners, joined The Raine Group as partner. Go deeper [...] â€¢ Topspin Consumer Partners invested in Grid, a Dallas-based maker of lockers and flooring solutions for fitness facilities. Go deeper â€¢ Victor Capital Partners invested in Specialty Fenestration Group, a maker of high-security windows and doors. River Associates Investments exited. Go deeper ğŸš‘ QC Capital Group invested in My Pediatric Doctor, a 24/7 urgent care pediatric telemedicine company. Go deeper ## M&A â€¢ ADT, a Boca Raton, Fla.-based home security company,acquired Origin Wireless, an AI company that can analyze and track motion without cameras, for $170m. Go deeper",
          "publishedAt": "Tue, 24 Feb 2026 20:59:41 GMT",
          "ts": 1771966781000,
          "tavilyScore": 1.5865913600000001,
          "summary": "â€¢ æ€»éƒ¨ä½äºåç››é¡¿çš„ç½‘ç»œå®‰å…¨å…¬å¸ Evoke Security ç­¹é›†äº† 400 ä¸‡ç¾å…ƒçš„ç§å­å‰èèµ„ï¼Œç”± Crosspoint Capital Partners é¢†æŠ•ï¼ŒRed Cell Partners å‚ä¸ã€‚",
          "judgement": {
            "frontier": 9,
            "depth": 6,
            "reach": 3,
            "total": 8.09659136
          },
          "tags": [
            "äººå·¥æ™ºèƒ½",
            "ç”Ÿç‰©æŠ€æœ¯"
          ],
          "score": 8.09659136
        },
        {
          "title": "Q4 2025 Pharma Biotools VC Trends - PitchBook",
          "titleZh": "2025 å¹´ç¬¬ 4 å­£åº¦ Pharma Biotools é£é™©æŠ•èµ„è¶‹åŠ¿",
          "source": "pitchbook.com",
          "link": "https://pitchbook.com/news/reports/q4-2025-pharma-biotools-vc-trends",
          "rawSummary": "Pharma biotools VC deal activity rebounded in 2025, with deal value reaching $5.7 billion and deal count surging to a record 537â€”signaling renewed investor confidence after three years of contraction. [...] The pharma biotools sector regained momentum in 2025 as venture funding rebounded following three years of contraction, driven by investor appetite for asset-light business models and AI-enabled technologies that support drug discovery and development. Deal value rose modestly for the year and remained stable in Q4, signaling a normalization of activity rather than renewed decline. Investment concentrated heavily in generative AI, quantum computing, microfluidics, and synthetic biology, as companies delivering high-fidelity data generation, automation, and software-like services attracted outsized interest. Major Q4 financings for AI-driven protein design platforms and automation-focused tools underscored how investors are backing the emerging â€œscientific stackâ€ that connects [...] M&A activity remained subdued, although Halozyme Therapeuticsâ€™ acquisition of Elektrofi for up to $900 million marked the sectorâ€™s largest exit since 2021 and highlighted continued demand for technologies embedded in biologics delivery and manufacturing workflows. China also emerged as a key growth market, with deal count rising more than 80% YoY and investment concentrated in AI-driven platforms and enabling infrastructure for next-generation therapeutics. Overall, pharma biotools VC activity is stabilizing as investors prioritize platforms capable of generating high-quality datasets, enabling automation, and accelerating commercialization across the broader biopharma ecosystem. Table of contents",
          "publishedAt": "Tue, 24 Feb 2026 19:25:21 GMT",
          "ts": 1771961121000,
          "tavilyScore": 1.59768992,
          "summary": "åˆ¶è¯ç”Ÿç‰©å·¥å…·é£é™©æŠ•èµ„äº¤æ˜“æ´»åŠ¨åœ¨ 2025 å¹´å‡ºç°åå¼¹ï¼Œäº¤æ˜“ä»·å€¼è¾¾åˆ° 57 äº¿ç¾å…ƒï¼Œäº¤æ˜“æ•°é‡æ¿€å¢è‡³åˆ›çºªå½•çš„ 537 ç¬”ï¼Œæ ‡å¿—ç€æŠ•èµ„è€…åœ¨ç»å†ä¸‰å¹´æ”¶ç¼©åä¿¡å¿ƒé‡æ‹¾ã€‚",
          "judgement": {
            "frontier": 7,
            "depth": 8,
            "reach": 3,
            "total": 7.927689920000001
          },
          "tags": [
            "äººå·¥æ™ºèƒ½",
            "ç”Ÿå‘½ç§‘å­¦",
            "ç”Ÿç‰©æŠ€æœ¯",
            "è›‹ç™½è´¨ç§‘å­¦",
            "ç§‘å­¦å‘ç°",
            "æŠ€æœ¯"
          ],
          "score": 7.927689920000001
        }
      ]
    }
  ]
}